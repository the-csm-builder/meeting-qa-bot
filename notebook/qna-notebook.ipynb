{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe content, video ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
    "import openai\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "This is a recording of a conversation between 5 people and 2 companies.\n",
    "Please transcribe the audio in the following format:\n",
    "\n",
    "'Person 1: <utterance>\n",
    "Person 2: <utterance>\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# Open the audio file\n",
    "audio_file = open(\"Vmcall.m4a\", \"rb\")\n",
    "\n",
    "# Transcribe the audio\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file, prompt=prompt)\n",
    "\n",
    "# Convert the transcript to a string\n",
    "transcript_string = str(transcript)\n",
    "\n",
    "# Print the transcript\n",
    "# (transcript)\n",
    "# Save the transcript to a file\n",
    "with open(\"transcript.txt\", \"w\") as f:\n",
    "    f.write(transcript_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the transcription ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import textwrap\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = \"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\"  # Replace with your actual key\n",
    "\n",
    "# User-provided information\n",
    "meeting_attendees = input(\"Please enter the meeting attendees: \")\n",
    "company_name = input(\"Please enter the company name: \")\n",
    "main_topic = input(\"Please enter the main topic: \")\n",
    "\n",
    "# Open the transcript file\n",
    "with open(\"../data/transcript.txt\", \"r\") as f:\n",
    "    transcript_string = f.read()\n",
    "\n",
    "# Define the size of chunks\n",
    "chunk_size = 2048  # Adjusted to be compatible with the new model's token limit\n",
    "\n",
    "# Split the transcript into chunks\n",
    "chunks = textwrap.wrap(transcript_string, chunk_size)\n",
    "\n",
    "# Open the output file\n",
    "with open(\"../data/summary.txt\", \"w\") as out_file:\n",
    "    # Write the user-provided information to the file\n",
    "    out_file.write(f\"Meeting Attendees: {meeting_attendees}\\n\")\n",
    "    out_file.write(f\"Company Name: {company_name}\\n\")\n",
    "    out_file.write(f\"Main Topic: {main_topic}\\n\\n\")\n",
    "\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        # Feed the chunk to the model in a conversation\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": f\"You are a helpful assistant that summarizes text, writes action items and emails. This text is from a meeting on the topic '{main_topic}' at '{company_name}', attended by {meeting_attendees}. Please summarize the following text: {chunk}\"\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Write the summary of each chunk to the file\n",
    "        summary = response['choices'][0]['message']['content']\n",
    "        out_file.write(f\"Summary of chunk {idx+1}:\\n{summary}\\n\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QNA with data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Four people attended the meeting.\n",
      "Answer:  The meeting was attended by 4 people and the company name was New Age Electronics. The main topic discussed was TechMate Solutions' new software features that could assist New Age Electronics in streamlining their production process. The meeting was divided into three parts discussing data analysis, automated report generation, and potential scorecards to improve team performance. TechMate Solutions representatives emphasized the software's flexibility to adapt to New Age Electronics' current system to make their production process more efficient.\n",
      "Answer:  Based on the meeting summary, some action items that could be considered are:\n",
      "\n",
      "1. Explore the implementation of TechMate Solutions' data analysis tool to identify bottlenecks in the production process and increase efficiency.\n",
      "2. Consult with TechMate Solutions to understand the customization options available for automated report generation and consider implementing this feature to save time for senior managers.\n",
      "3. Discuss creating a potential scorecard feature to provide a quick overview of team performance and explore data analysis by department to identify recurring issues and improve the production process.\n",
      "4. Identify key stakeholders who could be responsible for overseeing the software implementation and ensuring its successful integration into the current system.\n",
      "5. Schedule follow-up meetings with TechMate Solutions to discuss progress, address any challenges, and assess the effectiveness of the new software features in streamlining the production process.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = \"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\"  # Replace with your actual key\n",
    "\n",
    "# Open the summary file and read it\n",
    "with open(\"../data/summary.txt\", \"r\") as f:\n",
    "    summary_string = f.read()\n",
    "\n",
    "# Initialize conversation history with the summary\n",
    "conversation_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Be short and concise with responses.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"This is the summary of the meeting: {summary_string}\"},\n",
    "]\n",
    "\n",
    "# After writing all summaries, let the user ask questions\n",
    "while True:\n",
    "    user_question = input(\"You can ask a question about the summarized text. Type 'quit' to end: \")\n",
    "    if user_question.lower() == 'quit':\n",
    "        break\n",
    "\n",
    "    # Append the user question to the conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_question})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=conversation_history\n",
    "    )\n",
    "\n",
    "    # Get the assistant's message from the response and print it\n",
    "    answer = response['choices'][0]['message']['content']\n",
    "    print(\"Answer: \", answer)\n",
    "\n",
    "    # Append the assistant's answer to the conversation history\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
